{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import importlib\n",
    "import time\n",
    "import datetime\n",
    "import segment_cluster as sc\n",
    "import pandas as pd\n",
    "import os\n",
    "import fnmatch\n",
    "from scipy.stats import zscore\n",
    "\n",
    "importlib.reload(sc)\n",
    "sys.stdout.flush()\n",
    "np.random.seed(0)\n",
    "\n",
    "seg_lens=[10, 50, 100,150,200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_outlier = \"data/synthetic_rhos_v2.csv\"\n",
    "\n",
    "# datasets used, every item corresponds to one complete test of the algorithm\n",
    "outlier_datasets = [\"data/synthetic_flats.csv\", \n",
    "                    \"data/synthetic_boxes.csv\", \n",
    "                    \"data/synthetic_boxes_thick.csv\", \n",
    "                    \"data/synthetic_sines.csv\", \n",
    "                    \"data/synthetic_sines_low.csv\", \n",
    "                    \"data/synthetic_sines_long.csv\", \n",
    "                    \"data/synthetic_sines_short.csv\", \n",
    "                    \"data/synthetic_sines_low_long.csv\", \n",
    "                    \"data/synthetic_sines_low_short.csv\",\n",
    "                    \"data/synthetic_flats.csv\", \n",
    "                    \"data/synthetic_boxes.csv\", \n",
    "                    \"data/synthetic_sines.csv\"]\n",
    "\n",
    "rho_data = np.loadtxt(rho_outlier, delimiter=',')\n",
    "box_data = np.loadtxt(\"data/synthetic_boxes.csv\", delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = rho_data[0:50]\n",
    "all_train_segments=[]#loop throught the light curves of a given class and segments them\n",
    "for time_series in training_data:\n",
    "    train_segments=sc.segmentation(time_series, \n",
    "                                50, \n",
    "                                1,\n",
    "                                time_stamps=False)\n",
    "    all_train_segments.append(train_segments)\n",
    "all_train_segments=np.vstack(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='auto', kernel='rbf',\n",
       "      max_iter=-1, nu=0.05, random_state=None, shrinking=True, tol=0.001,\n",
       "      verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "OCSVM = svm.OneClassSVM(nu=0.05, kernel=\"rbf\")\n",
    "OCSVM.fit(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_rho = rho_data[200:250]\n",
    "all_valid_rho_segments=[]#loop throught the light curves of a given class and segments them\n",
    "for time_series in training_data:\n",
    "    train_segments=sc.segmentation(time_series, \n",
    "                                50, \n",
    "                                1,\n",
    "                                time_stamps=False)\n",
    "    all_valid_rho_segments.append(train_segments)\n",
    "all_valid_rho_segments=np.vstack(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_box = box_data[0:50]\n",
    "all_valid_box_segments=[]#loop throught the light curves of a given class and segments them\n",
    "for time_series in training_data:\n",
    "    train_segments=sc.segmentation(time_series, \n",
    "                                50, \n",
    "                                1,\n",
    "                                time_stamps=False)\n",
    "    all_valid_box_segments.append(train_segments)\n",
    "all_valid_box_segments=np.vstack(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_rho = OCSVM.predict(all_valid_rho_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_box = OCSVM.predict(all_valid_box_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([18040,  4510]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_box, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([18040,  4510]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_rho, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_data = np.loadtxt(\"data/synthetic_flats.csv\", delimiter=',')\n",
    "valid_data_flat = flat_data[0:50]\n",
    "all_valid_flat_segments=[]#loop throught the light curves of a given class and segments them\n",
    "for time_series in training_data:\n",
    "    train_segments=sc.segmentation(time_series, \n",
    "                                50, \n",
    "                                1,\n",
    "                                time_stamps=False)\n",
    "    all_valid_flat_segments.append(train_segments)\n",
    "all_valid_flat_segments=np.vstack(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_flat = OCSVM.predict(all_valid_flat_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1,  1]), array([18040,  4510]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(predict_flat, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyod\n",
    "from pyod.models.loci import LOCI\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_segments = np.vstack((all_valid_rho_segments, all_valid_box_segments, all_valid_flat_segments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LocalOutlierFactor(algorithm='auto', contamination=1e-10, leaf_size=300,\n",
       "                   metric='minkowski', metric_params=None, n_jobs=None,\n",
       "                   n_neighbors=50, novelty=True, p=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOF = LocalOutlierFactor(n_neighbors=50, algorithm=\"auto\", leaf_size=30, metric=\"minkowski\", p=2, metric_params=None, contamination=1e-10, novelty=True, n_jobs=None)\n",
    "LOF.fit(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1]), array([67650]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(LOF.predict(validation_segments), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/data/jakubok/software/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:247: FutureWarning: behaviour=\"old\" is deprecated and will be removed in version 0.22. Please use behaviour=\"new\", which makes the decision_function change to match other anomaly detection algorithm API.\n",
      "  FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    6.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='old', bootstrap=False, contamination=0.0,\n",
       "                max_features=1.0, max_samples='auto', n_estimators=1000,\n",
       "                n_jobs=None, random_state=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IF = IsolationForest(n_estimators=1000, max_samples=\"auto\", contamination=0., max_features=1.0, bootstrap=False, n_jobs=None, behaviour=\"old\", random_state=None, verbose=1, warm_start=False)\n",
    "IF.fit(all_train_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/export/data/jakubok/software/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/iforest.py:415: DeprecationWarning: threshold_ attribute is deprecated in 0.20 and will be removed in 0.22.\n",
      "  \" be removed in 0.22.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([1]), array([67650]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(IF.predict(validation_segments), return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training-test outcome of MSE: compare test variance\n",
    "rho-flat bad:low\n",
    "rho-box bad:low\n",
    "rho-widebox ok:low\n",
    "rho-sines good:same\n",
    "rho-smallsine bad:low\n",
    "rho-widesine good:same\n",
    "rho-narrowsine good:same\n",
    "rho-smallwidesine bad:low\n",
    "rho-smallshortsine bad:low\n",
    "flat-rho good:high\n",
    "box-rho ok:high\n",
    "sine-rho bad:same\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f7e5664ab41b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train on flat, test against rho\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtsscod_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTSSCOD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mflat_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data/synthetic_flats.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtsscod_flat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
     ]
    }
   ],
   "source": [
    "#train on flat, test against rho\n",
    "tsscod_flat = sc.TSSCOD(k_clusters = 10, seg_len = 100)\n",
    "flat_data = np.loadtxt(\"data/synthetic_flats.csv\", delimiter=',')\n",
    "tsscod_flat.train(flat_data[0:150], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "\n",
    "x = np.array([[1,1], [2,2], [3,3], [4,4], [5,5]])\n",
    "y = np.array([[2,2], [3,3], [4,4]])\n",
    "distance, path = fastdtw(x, y, dist=euclidean)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
